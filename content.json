{"pages":[{"title":"Hello Traveler!","path":"404.html","permalink":"https://iramellor.com/404.html","excerpt":"","keywords":"","text":"You appear to be lost. Try going back to the home page here."},{"title":"About Me","path":"about/index.html","permalink":"https://iramellor.com/about/index.html","excerpt":"","keywords":"","text":"Name pronunciation: Ira (Eye-ruh)Internet moniker: RollemIra What do I do? I’m now a proud business co-founder at Heave.co! We’re revoulutionizing heavy equipment service and repair. Download the app and within 10 minutes book a qualified technician to be on site as soon as the next day! Helping the construction industry #DefeatDowntime I’m also a long time .NET developer that dabbles in other technologies from time to time. I also know lots of other things like NodeJS, TypeScript, Python, and lots of SQL flavors. Basically any technology that catches my eye and I think could be useful. My passion for learning is a big help in the ever evolving tech industry. My current focus is enterprise cloud, automation and DevOps. Aiding in taking companies to the cloud and securing their long-term future within it through DevOps and Automation. What about hobbies?I love to get out and do things like go to Busch gardens, go boating, to the park, the beach or even the pool. Summer get’s hot in Florida so I mostly like to do things involving water. Anything else?Yes, I’m a proud father! It’s demanding and so rewarding."}],"posts":[{"title":"Oracle Public Cloud Instance Information Collector","slug":"Oracle-Public-Cloud-Instance-Information-Collector","path":"2019/03/26/Oracle-Public-Cloud-Instance-Information-Collector/","permalink":"https://iramellor.com/2019/03/26/Oracle-Public-Cloud-Instance-Information-Collector/","excerpt":"","keywords":"","text":"The PrefaceIn my time with Oracle, the company shifted it’s course from OCI-Classic to onboarding all new customers, and migrating current customers to OCI. This would provide some challenges for current customers as they would require an exercise in taking inventory of their current cloud resources. This would help in capacity planning for their future in Oracle’s cloud. Some customers kept up to date spreadsheets of all their current services in OCI-C, while others were seeking help with a more automated approach at mapping their current OCI-C resources. The SituationI was assigned to help a customer with their capacity planning for migration. They were in need of some information that Oracle couldn’t provide (as it was beyond a security boundary) and other information that could be provided programmatically using the OPC API. I was determined to give this customer the most information that could be provided in an automated fashion. They were specifically interested in their IaaS compute instances and collecting metadata information about them. I figured a simple CLI application could do the trick. The SolutionI was able to cobble together a NodeJS application that could be configured with endpoint information, check the user’s credentials and pull all the necessary information down from the API. Once that was done, we could introspect it for the specific information we were looking for and write it to a simple CSV file. If you’re on OCI-C and need to collect your own IaaS instance information, hopefully this tool can help you too! Click to check the Repo out on GitHub"},{"title":"Task Running Windows Service in .NET","slug":"Task-Running-Windows-Service-in-NET","path":"2017/08/09/Task-Running-Windows-Service-in-NET/","permalink":"https://iramellor.com/2017/08/09/Task-Running-Windows-Service-in-NET/","excerpt":"","keywords":"","text":"The PrefaceI bought a new computer a while back. I do a lot of file moving&#x2F;manipulation&#x2F;cleanup on my home PC because I’m an avid Plex user. For these tasks I simply use .bat or .cmd files and the Windows task scheduler. It’s quite a simple solution and generally runs like clock work. Until it doesn’t and you can’t understand why. First AttemptAfter some internet searches I stumbled across the Tweaking.com windows repair program that offered fixes and had quite a few recommendations. With my fingers crossed I installed the app and tried it out. It did not fix my Windows task scheduler problem. But I did end up buying a license for it because it’s an amazing piece of software that does a lot of optimizations. Coding Your OwnTime to think about rolling my own. What do I need this thing to do? Always be running Run .bat or .cmd files on an interval So for #1 something always running, I immediately think Windows service. I’ve long used TopShelf for this sort of thing. It’s highly configurable and easy to use. For #2 I considered using Quartz.NET, but I thought it would be overkill. I just rolled my own interval and tracking code. I specifically needed to run .bat and .cmd files, for this I found a project called MedallionShell. It runs commands in threads within your application. You could use it for parallelism, but I decided not to introduce that complexity into my simple use case. LearningThis project brought some fun learning aspects. I was able to implement builds using Cake builds for C# and also automate my builds using AppVeyor. With all of this in place it will build my code and put a release on GitHub for me. Pretty nifty! Even got some badges working on the project home page. ConclusionI learned a lot doing this simple little project and had a lot of fun doing it. I wish I knew why the Windows task scheduler doesn’t run my tasks. I guess as long as it runs all of the other important ones, I can be good with that. Click to check the Repo out on GitHub"},{"title":"Getting MEAN With TypeScript","slug":"Getting-MEAN-With-TypeScript","path":"2017/03/09/Getting-MEAN-With-TypeScript/","permalink":"https://iramellor.com/2017/03/09/Getting-MEAN-With-TypeScript/","excerpt":"","keywords":"","text":"I have been doing a lot of research into the MEAN stack as of late in hopes of possibly using in on my next project. First I wanted to see if using TypeScript was viable, because I come from a .NET background and strong types help me find problems at compile time. Then I wanted to see if I could get some sort of debugging experience. I remember the good ol’ days of Classic ASP scripting and having to debug write everything so I could get a picture of what was happening. Editor(s)So many to choose from in this department. Personally I chose WebStorm because it afforded me that debugging experience I was looking for in the IDE. SublimeText and VS Code are excellent options as well, but like I said… Debugging. Getting LessonsMy first round of searches brought me to an excellent video tutorial by Brad Traversy on MEAN Stack Front To Back. It’s a series in which you’ll use ES6 to create a MEAN stack application that does some simple authentication. It’s a great series, I highly suggest watching it and checking out the code here. It uses ES6 and like I said, I’m looking for TypeScript. My next round of searching brought me to Brian Love’s blog where he has an article TypeScript2 + Express + Mongoose + Mocha + Chai. Whew! That’s a mouth full, and a lot of tech to learn. It’s a fantastic article about combining all those technologies to get a running MEAN stack application with testing. Check out his article here and certainly check out the code here. ComboMy mission was to combine the two projects to make one MEAN application with a TypeScript and test driven backend and an Angular2 front end. I was able to take the lessons learned about TypeScript, Grunt, Mocha and Chai and apply it to the meanauthapp created in Brad’s videos. It makes for very easy and type-safe development with NodeJS. Big thanks to both Brian and Brad for their work! Click to check the Repo out on GitHub"},{"title":"Dead Letter Management With Azure Service Bus","slug":"Dead-Letter-Management-With-Azure-Service-Bus","path":"2017/02/21/Dead-Letter-Management-With-Azure-Service-Bus/","permalink":"https://iramellor.com/2017/02/21/Dead-Letter-Management-With-Azure-Service-Bus/","excerpt":"","keywords":"","text":"Isn’t the whole point of durable, reliable messaging that we can re-queue a message for processing?– Me The BackgroundI recently got involved in a project using Azure Service Bus. The premise was simple, run service bus queue messages through a WebJob durably and reliably. For this project I ended up using the Topics feature for a publish&#x2F;subscribe model. I got the project up and running fairly quickly thanks to the WebJobs SDK. By default the message will be attempted 10 times and then automatically sent to the DeadLetter queue. So to test this, I throw an exception during message processing and sure enough it goes as expected. I now have a message in the DeadLetter queue. In the Azure Management Portal I can see the message exists where it’s supposed to. As of the writing of this article the Azure Management Portal only supports changing the properties of Topics and not managing the messages in them. Supplemental SoftwareWhat I need is a piece of software that will let me manage the messages in the queue. I could write it myself, but this seems like a task there would be a tool for. My first round of searches dug up Service Bus Explorer. It’s a free Service Bus management tool. It looks like a great piece of well thought out management software, but I was unable to get the DeadLetter Repair and Resubmit Message to work properly for me. Update: After a bit of digging about BrokeredMessage serialization I was able to find this article on StackOverflow explaining how to dictate how Azure Service Bus handles my message content. After implementing that Service Bus Explorer is working like a charm. My next round of digging brought me to Azure Management Studio. This is a paid piece of management software that helps manage more than just your Service Bus. This tool was able to properly copy and re-submit the queue message back to it’s Topic of origin. Success! Side NoteIf Domain Driven Design and Message Queues are highly important to your system, you may want to check out NServiceBus. I just needed some bolt-on queues for middleware which is why I decided to just tackle queueing on my own. Happy coding!"},{"title":"WooCommerce API Using RestSharp Over HTTP With OAuth","slug":"WooCommerce-API-Using-RestSharp-over-HTTP-with-OAuth","path":"2016/11/18/WooCommerce-API-Using-RestSharp-over-HTTP-with-OAuth/","permalink":"https://iramellor.com/2016/11/18/WooCommerce-API-Using-RestSharp-over-HTTP-with-OAuth/","excerpt":"","keywords":"","text":"Now after searching NuGet I saw that there is a C# WooCommerce library out there all ready written called WooCommerce.NET. This isn’t going to work for me because I will need the ability to gain access to custom Order fields. So I decided to just use my favorite REST client RestSharp to contact a fairly simple REST API for WooCommerce. But I was running into a strange authentication issue and being denied authentication with a 401 status code. Now, first a disclaimer… DO NOT USE HTTP FOR WooCommerce IN A PRODUCTION ENVIRONMENT! Ok, but I need to do some testing in a local environmnet so I can see that my code is working properly. Reading the WooCommerce documentation for authentication, which can be found here, it clearly states: The OAuth parameters must be added as query string parameters and not included in the Authorization header. This is because there is no reliable cross-platform way to get the raw request headers in WordPress. So I do a bit of digging about RestSharp and OAuth1.0 and come up with this suite of tests. Here’s the important bit that I needed: 123456789101112131415161718192021222324252627[Test]public void Can_Authenticate_OAuth1_With_Querystring_Parameters()&#123; const string consumerKey = &quot;enterConsumerKeyHere&quot;; const string consumerSecret = &quot;enterConsumerSecretHere&quot;; const string baseUrl = &quot;http://restsharp.org&quot;; var expected = new List&lt;string&gt; &#123; &quot;oauth_consumer_key&quot;, &quot;oauth_nonce&quot;, &quot;oauth_signature_method&quot;, &quot;oauth_timestamp&quot;, &quot;oauth_version&quot;, &quot;oauth_signature&quot; &#125;; RestClient client = new RestClient(baseUrl); RestRequest request = new RestRequest(Method.GET); var authenticator = OAuth1Authenticator.ForRequestToken(consumerKey, consumerSecret); authenticator.ParameterHandling = OAuthParameterHandling.UrlOrPostParameters; authenticator.Authenticate(client, request); var requestUri = client.BuildUri(request); var actual = HttpUtility.ParseQueryString(requestUri.Query).AllKeys.ToList(); Assert.IsTrue(actual.SequenceEqual(expected));&#125; The above Authenticate method will do all the work and add all the parameters I need. But wait… Something’s not right here. In the debugger it shows me that the parameters on the request are being added as cookes: Strange, but ok. So I decided to make an extension method that does all the authentication, gets all the parameters added to the request, and then converts them to QueryString parameters. 123456789101112131415161718public static class RestRequestExtensions&#123; public static RestRequest BuildOAuth1QueryString(this RestRequest request, RestClient client, string consumerKey, string consumerSecret) &#123; var auth = OAuth1Authenticator.ForRequestToken(consumerKey, consumerSecret); auth.ParameterHandling = OAuthParameterHandling.UrlOrPostParameters; auth.Authenticate(client, request); //convert all these oauth params from cookie to querystring request.Parameters.ForEach(x =&gt; &#123; if (x.Name.StartsWith(&quot;oauth_&quot;)) x.Type = ParameterType.QueryString; &#125;); return request; &#125;&#125; So the code to build a request now looks something like this. 1234var client = new RestClient(&quot;http://example.com/api/v1&quot;);var request = new RestRequest(&quot;/path/to/resource&quot;);request.BuildOAuth1QueryString(client, &quot;&#123;consumer_key&#125;&quot;, &quot;&#123;consumer_secret&#125;&quot;);var response = client.Execute(request); And there we have it. Talking to WooCommerce with RestSharp. For ProductionI can not stress enough to not communicate over HTTP in production. In production, you should be using HTTPS. In that case you can use HTTP Basic Authentication. Then you will no longer need the BuildOAuth1QueryString extension method, you would simply add the Basic Authentication to the client like so: 12//Basic over Httpsclient.Authenticator = new HttpBasicAuthenticator(&quot;&#123;consumer_key&#125;&quot;, &quot;&#123;consumer_secret&#125;&quot;); Hope this helps!"},{"title":"The Developer's Feed","slug":"The-Developer-s-Feed","path":"2016/11/17/The-Developer-s-Feed/","permalink":"https://iramellor.com/2016/11/17/The-Developer-s-Feed/","excerpt":"","keywords":"","text":"Every day in the ever changing world of technology and development, I try to do some reading to keep up with the world around me. I have worked in places with small teams and big teams, but my current situation puts me as the only person with development skills in my current company. It’s really important in this situation, not to lose touch with the world of development around you. This feed has kept me up to date with new tech and also taught me even more about tech I all ready thought I knew. I’ve been curating this list of blog feeds since I became a developer a long time ago, so many of them may be out-dated. Still, there are always great articles popping up for me to read and dabble in the tech if I have the time. Personally I use Feedly for my RSS reader, but the file should easily import into your favorite RSS reader. Developer Feed File - You may need to Right Click -&gt; Save As Anyhow, hope you enjoy!"},{"title":"The Need to Knows of Developers","slug":"The-Need-to-Knows-of-Developers","path":"2016/11/16/The-Need-to-Knows-of-Developers/","permalink":"https://iramellor.com/2016/11/16/The-Need-to-Knows-of-Developers/","excerpt":"","keywords":"","text":"I was talking to a friend the other day about what you need to know to be an effective developer. We touched on topics like source control, people skills, presentation skills and a ton of other skills that are inherent things that are need to know. Other things could include frameworks, good blog sites, or how to get what you’re asking for from your boss. After a while we got into the code aspect of being a developer. Where do you start? What is a waste of time to learn? When should I know what? Well, I certainly don’t know the best way but I’ll share the order that worked for me. Let’s just start basic. The first thing you should know about developing for whatever it is you want to write code for is the syntax of the language you’ll be using. Start simple, think “Hello World”. If you’re learning an Object Oriented language (like C#), your next stop should be The four pillars of Object Oriented Design Abstraction Polymorphism Inheritance Encapsulation Once you have an understanding of the 4 pillars in my opinion your next stop should be learning the SOLID principles Single responsibility principle Open&#x2F;closed principle Liskov substitution principle Interface substitution principle Once you’ve gotten to principles you can start to make more maintainable code in larger projects. Finally, once you’ve gotten those down it’d be best to look into the Gang of Four Design Patterns. These are proven patterns for enterprise scale production systems. If you have a good understanding of the problem you’re trying to solve, there’s a good chance a combination of these patterns will help you solve it. All of this being said, there are problems you come across time and again as a developer. One of the biggest ones I face often is that of cross cutting concerns. I have this thing that does one thing, but now needs to do another. For example, you have data going into a database and you’d like to audit who put the record in with some sort of logging. In this case there are many solutions, and you could even write your own using all those spiffy patterns. Or in my case I found a great library called MediatR that implements a nice architecture solving that problem for me. Sometimes with the right amount of digging you’ll find a good library that solves the recurring problems. UpdateIt is almost imperative now to know about cloud architecture for hightly available and scalable applications. I had the pleasure of reconnecting with a former colleague of mine who so happens to be a cloud architect at Microsoft. He pointed me toward his GitHub for some guidance on Microsoft Azure cloud architecture. You can see the repository on his GitHub here. Happy coding!"},{"title":"Blog Up and Running With Hexo!","slug":"Blog-up-and-running-with-Hexo","path":"2016/11/15/Blog-up-and-running-with-Hexo/","permalink":"https://iramellor.com/2016/11/15/Blog-up-and-running-with-Hexo/","excerpt":"","keywords":"","text":"I’ve been working with a lot of NodeJS stuff lately in my off time using things like Bower, Grunt, Gulp, etc… It’s been a nice break from my usual .NET stuff. It’s been a long while since I had my site up, running and full functional with a blog and everything. I’m not sure how much I’ll use it, but I used to put a lot of time and energy into blog posts. Maybe I’ll see if I can recover those old posts somehow. But for now I’m up and running with GitHub Pages and Hexo. You can find more about hexo at http://hexo.io UpdateI was able to get some, but not all of my old posts back. It took a lot of digging and code re-formatting but it was worth it. Took some time learning EJS and Hexo template stuff, but the site is looking nice."},{"title":"From Coder to PM or Architect","slug":"From-Coder-to-PM-or-Architect","path":"2011/09/19/From-Coder-to-PM-or-Architect/","permalink":"https://iramellor.com/2011/09/19/From-Coder-to-PM-or-Architect/","excerpt":"","keywords":"","text":"The CoderMuch like everyone else, I started my career as a coder. Rob Conery from Tekpub has a great series on going from coder to developer here. Being the coder has it’s up sides, low responsibilities being one of them. If you just like to do what you do and go home, then there is no need to move up for you here. This usually consists of taking strict written or verbal requirements and turning them into a bit of code. This person is usually in charge of testing too. You usually are under at least one person who guides you a lot. But if you aspire to do more, you will most likely want to become a developer. The DeveloperThe developer has a lot more decision making power when it comes to both requirements and system architecture. In most scenarios, a discovery phase of a project is done and then all of that is in turn made into functional requirements. The developer can be called upon to both try to make requirements from the discovery documents or review functional requirements for refinement. The developer also has a bit more reign when it comes to speaking to clients and making bigger decisions in system architecture and implementation. The ArchitectThe architect has the ultimate power when it comes to the system architecture. This is the person called upon to solve the really complex problems. Usually the most talented person that codes for the hardest problems, but overall probably writes the least amount of code on the project. This sometimes isn’t by choice. A lot of the time it is due to the fact that this person is usually in charge of peer code reviews and other administrative duties. Especially duties of discovery and helping find all of the functional requirements. The architect also weighs the risks of implementing new technologies into the system. This person usually has the last call on what technologies go into the system, and what is left out. The Project ManagerThe PM is the person usually in charge of documentation and collaboration. Documenting the current processes through the discovery phase and then working with whom ever they need to to make a functional requirements document out of it. The PM does a lot of system testing to make sure everything passes to spec. The keep a constant watch over the project and budget to make sure that the client stays happy and the project comes in on budget. The DecisionStarting out as a coder, you usually climb up the latter to a PM or an Architect. If you are in an unfortunate situation then sometimes you have to do it all. Depending on the type of person you are and your desires as a professional, you will choose different paths out of the coder role. I myself am finding that I’m having a hard time with the PM duties because I like to stay more on the technical side of things. I’m not sure if that may change in the future, but for now my next move up is most likely looking to be an Architect. ConclusionThere comes a point in time as a coder where you will need to make a decision on which way is up. This decision will be made not only for career advancement, but also for some extra padding in the salary department. When that time comes you may be asked to try some things out that you may or may not love. I suggest you give it a good shot because you never know, some things might grow on you."},{"title":"Website Move and Software Change","slug":"Website-Move-and-Software-Change","path":"2011/09/18/Website-Move-and-Software-Change/","permalink":"https://iramellor.com/2011/09/18/Website-Move-and-Software-Change/","excerpt":"","keywords":"","text":"I recently canceled my account for a VPS in lieu of shared hosting. I was dropping a bunch of websites and didn’t really need a VPS anymore. So I figured I hadn’t touched my website in a while so I thought I’d kick it back up a notch. Aside from a domain name change (major SEO foul, I know), I also decided on a software change for managing my website. BlogEngine.NETI was using BlogEngine.NET as my blog software. It actually worked really well, I had no real complaints. The only thing for me was that it wasn’t easily customized. By easy I mean pure and simple customizations. I was on a previous version of it because I hadn’t touched the site in a while, so I’m not sure if this has change or how much in later releases. OrchardI chose to go with the Orchard software for my new site. It is full featured and is very easily customized with modules and theme. It’s taken some getting use to, but everything I need to learn is pretty much in the Dashboard of Orchard. There are quite a few articles out there on getting started with Orchard, but a series I found particularly helpful was written by John Papa. You can find it here: http://johnpapa.net/orchardpart1 I’m thinking it will be a bit of an adventure still getting into this. The export and import of my blog worked out nicely. So from here on in, it’s Orchard or bust! UpdateMoved it again to Hexo, see this post for more details."},{"title":"Avoiding the Database Deployment Nightmare","slug":"Avoiding-The-Database-Deployment-Nightmare","path":"2009/06/18/Avoiding-The-Database-Deployment-Nightmare/","permalink":"https://iramellor.com/2009/06/18/Avoiding-The-Database-Deployment-Nightmare/","excerpt":"","keywords":"","text":"So, I have written before about how to put your database into version control using database projects in Visual Studio. Even while having the scripts in the solution, there can be times when you can’t exactly remember what you changed and needs to go out with your project deployment to the production database. Deploying files is easy because of tools like WinMerge, however deploying things to a database can get quite complicated. You could script both schemas and use WinMerge to see the differences between the development database and the production database. But even doing that, you will still have to write a custom script to get the production database schema up to date. Enter xSqlxSQLSoftware This is where a tool such as xSQL Object can be extremely helpful. All that need be done is set up the connections, run the comparison, and then you can visually see what has changed between your development and live databases! No need to remember what you changed or any of that, just run the comparison and execute the change script. It will even allow you to save database snapshots before running your change scripts. You can see an excellent walkthrough here. xSQL Object also comes in a bundle with another one of their products, xSQL Data or by it’s self. xSQL Data allows you to compare data differences between two databases. The Best PartAll the goodness of the xSQL Bundle (xSQL Object and xSQL Data) Lite Edition comes at a very affordable price FREE! If you only use SQL express edition then you can get the full bundle lite edition and it will work without any restrictions at all! However, if you need to use it against other versions of SQL Server it does have the following limitations: up to 25 tables up to 40 views up to 40 stored procedures up to 40 functions If you are using it against a small database then you shouldn’t have any problems. Now if you have databases larger than this and are using SQL Server editions other than express, the product costs $399.00 for a single user license. BUT, after downloading it I was sent an email offering 30% off if I purchased the product within 7 days of the download. That brings the cost down to $280! Not too bad when you compare it with the prices of other comparable tools. So I ask you to go to the website and check it out if you haven’t already! http://www.xsqlsoftware.com UpdateAfter contacting the company about licensing, I was shown another one of their great tools. A little while back I wrote a post titled Finding Text in SQL Server Stored Procedures. They have a tool called xSQL Object Search that allows you to search for all object types, through the names and definitions, for strings. It will also do a search using regular expressions! Pretty powerful stuff for a **FREE **tool! Check it out here: xSQL Object Search Happy Deployments!"},{"title":"The HttpWebRequest and Using Client Certificates","slug":"The-HttpWebRequest-and-Using-Client-Certificates","path":"2009/04/27/The-HttpWebRequest-and-Using-Client-Certificates/","permalink":"https://iramellor.com/2009/04/27/The-HttpWebRequest-and-Using-Client-Certificates/","excerpt":"","keywords":"","text":"So you may have found yourself in a similar situation, needing to make a TCP&#x2F;IP request to a 3rd party API possibly using SSL. Well, that is a quite simple task. It can however, be complicated if this 3rd party requires the use of certificates for communication to its API server. I found myself in some sort of certificate hell where I had the certificate, added it to the request and somehow it still wasn’t working. If you know what I’m talking about and had as many hurdles as I did, my condolences to you. I will try to explain in this article how I started, the problems I ran into and then the overall solution that ended up working for me. To start with, you should have some kind of certificate. Most likely a *.pfx or *.p12 file. This can also come with a private key or password for the certificate’s encryption. This is what a standard WebRequest over SSL might look like: 1234567891011121314151617181920212223242526public string GetData(string inputData)&#123; //will hold the result string result = string.Empty; //build the request object HttpWebRequest request = (HttpWebRequest)WebRequest.Create(&quot;https://someapi.com/&quot;); //write the input data (aka post) to a byte array byte[] requestBytes = new ASCIIEncoding().GetBytes(inputData); //get the request stream to write the post to Stream requestStream = request.GetRequestStream(); //write the post to the request stream requestStream.Write(requestBytes, 0, requestBytes.Length); //build a response object to hold the response //submit the request by calling get response HttpWebResponse response = (HttpWebResponse)request.GetResponse(); //get the response stream to read the response from Stream responseStream = response.GetResponseStream(); //now read it out to our result using (StreamReader rdr = new StreamReader(responseStream)) &#123; //set the result to the contents of the stream result = rdr.ReadToEnd(); &#125; //return return result;&#125; The example above is missing the portion where you add the certificate to the request. You may receive a 403 Forbidden error from the server if a certificate is required to make the request to the API server. A simple way of adding a certificate to the request would be like so: 12//add certificate to the requestrequest.ClientCertificates.Add(new X509Certificate(@&quot;C:\\certs\\Some Cert.p12&quot;, @&quot;SecretP@$$w0rd&quot;)); The X509Certificate class is found in the System.Security.Cryptography.X509Certificates namespace. Simply add a new certificate to the client certificates before calling for the response, and it should be sent with the request. However, you may encounter an exception with the message “The system cannot find the file specified”. I encountered this error after I got the application off my local machine and onto the development server. After doing some research I stumbled upon this kb article. This article opened my eyes to how using certificates is a little more complicated than I initially thought. Turns out the problem was that the user trying to access the certificate does not have a profile loaded. After stepping through the article, installing the certificate to the local machine’s personal certificate store, and then granting rights to the certificate using the WinHttpCertCfg.exe tool, and putting in a little more code found in the kb article, I was well on my way. The article describes how to use C# to open a certificate store and use the certificate directly out of the store. This presents a bit more elegant, and in my opinion more secure, way of getting to and using the certificate. 123456//add it in a better wayX509Store certStore = new X509Store(&quot;My&quot;, StoreLocation.LocalMachine);certStore.Open(OpenFlags.ReadOnly | OpenFlags.OpenExistingOnly);X509Certificate2 cert = certStore.Certificates.Find(X509FindType.FindBySubjectName, &quot;My cert subject&quot;, false)[0];certStore.Close();request.ClientCertificates.Add(cert); This method will not only give access to the certificate regardless of having a loaded profile, but it also takes the certificate’s private key password out of the code and&#x2F;or configuration. This snippet above took me out of the certificate hell that was crushing my life for a couple days! Putting it all together: 12345678910111213141516171819202122232425262728293031323334public string GetData(string inputData)&#123; //will hold the result string result = string.Empty; //build the request object HttpWebRequest request = (HttpWebRequest)WebRequest.Create(&quot;https://someapi.com/&quot;); //add certificate to the request //request.ClientCertificates.Add(new X509Certificate(@&quot;C:\\certs\\Some Cert.p12&quot;, @&quot;SecretP@$$w0rd&quot;)); //add it in a better way X509Store certStore = new X509Store(&quot;My&quot;, StoreLocation.LocalMachine); certStore.Open(OpenFlags.ReadOnly | OpenFlags.OpenExistingOnly); X509Certificate2 cert = certStore.Certificates.Find(X509FindType.FindBySubjectName, &quot;My cert subject&quot;, false)[0]; certStore.Close(); request.ClientCertificates.Add(cert); //write the input data (aka post) to a byte array byte[] requestBytes = new ASCIIEncoding().GetBytes(inputData); //get the request stream to write the post to Stream requestStream = request.GetRequestStream(); //write the post to the request stream requestStream.Write(requestBytes, 0, requestBytes.Length); //build a response object to hold the response //submit the request by calling get response HttpWebResponse response = (HttpWebResponse)request.GetResponse(); //get the response stream to read the response from Stream responseStream = response.GetResponseStream(); //now read it out to our result using (StreamReader rdr = new StreamReader(responseStream)) &#123; //set the result to the contents of the stream result = rdr.ReadToEnd(); &#125; //return return result;&#125; Hope this helps!"},{"title":"Finding Text in SQL Server Stored Procedures","slug":"Finding-Text-in-SQL-Server-Stored-Procedures","path":"2009/04/12/Finding-Text-in-SQL-Server-Stored-Procedures/","permalink":"https://iramellor.com/2009/04/12/Finding-Text-in-SQL-Server-Stored-Procedures/","excerpt":"","keywords":"","text":"So, I’m sure you have been met with a similar scenario during development. You know the one that you have to rename a column or even drop a column in the database. This can be quite annoying if you are doing stored procedure based data access for your application. Once you change the column on the table, you have to figure out which stored procedures reference the column. They aren’t always tough to find most of the time, but sometimes you are dealing with a column that may be referenced in many stored procedures. Well thanks to my boss Cliff’s research and knowledge sharing, your search can be as easy as ours! The query: 1234567891011USE NorthwindGO DECLARE @SearchText AS VARCHAR(50)SET @SearchText = &#x27;CustomerID&#x27;SELECTROUTINE_NAME,ROUTINE_DEFINITIONFROM INFORMATION_SCHEMA.ROUTINESWHERE ROUTINE_NAME LIKE &#x27;%&#x27; + @SearchText + &#x27;%&#x27;OR ROUTINE_DEFINITION LIKE &#x27;%&#x27; + @SearchText + &#x27;%&#x27; This query will return all the names and routine definitions of stored procedures that contain certain text. It is not really bound by column names but I needed a true development scenario. Run the query with what you are looking for and presto! All the stored procedures you will need to modify. Hope this helps!"},{"title":"SQL Server Side Paging With a Validated Dynamic Order By","slug":"SQL-Server-Side-Paging-With-A-Validated-Dynamic-Order-By","path":"2008/12/12/SQL-Server-Side-Paging-With-A-Validated-Dynamic-Order-By/","permalink":"https://iramellor.com/2008/12/12/SQL-Server-Side-Paging-With-A-Validated-Dynamic-Order-By/","excerpt":"","keywords":"","text":"So this is what it has come to anymore. Everyone is all about server side paging via SQL Server. As well they should be! It is so much faster and more efficient than having ADO or ADO.NET bring back a ton of records and then chop it to page it. However, there has always been some problems when trying to accomplish this task, especially using a SQL database that is pre 2005. This task is easier to accomplish in SQL 2005 and 2008 using the ROW_NUMBER() function. The part that gets flaky is having a dynamic order by clause in your SQL statement. Unfortunately, the only way to accomplish this is to write some dynamic SQL. In doing so, It can be hard to tell if the order by parameter received by the stored procedure is a valid one for the table you are selecting from. SolutionEnter the &quot;IsValidOrderBy&quot; user-defined function. This is a little function that will tell you if the column and order in the dynamic order by parameter is a valid one for the select statement you are running. 123456789101112131415161718192021222324252627282930313233343536373839CREATE FUNCTION [dbo].[udf_OrderByExists] ( @TableName NVARCHAR(50), @OrderBy NVARCHAR(50))RETURNS BITASBEGIN DECLARE @Result BIT SET @Result = 0 DECLARE @TableColumns TABLE ( [ColumnNameAndSort] NVARCHAR(100) NOT NULL ) INSERT INTO @TableColumns SELECT [Name] FROM syscolumns WHERE ID = OBJECT_ID(@TableName) INSERT INTO @TableColumns SELECT [Name] + &#x27; ASC&#x27; FROM syscolumns WHERE ID = OBJECT_ID(@TableName) INSERT INTO @TableColumns SELECT [Name] + &#x27; DESC&#x27; FROM syscolumns WHERE ID = OBJECT_ID(@TableName) IF EXISTS(SELECT [ColumnNameAndSort] FROM @TableColumns WHERE [ColumnNameAndSort] = @OrderBy) SET @Result = 1 RETURN @Result END Here you can see that we are taking 2 inputs. The first one being the table name you are selecting from, and the second being the order by clause received by the stored procedure. The function will then return a bit telling you if the column and order was found for the table you are selecting from. ExampleA simple example of using this user defined function would be selecting from a table of products. In that case, your stored procedure could look like so 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253CREATE PROCEDURE [dbo].[usp_GetProductsPaged] @SortExpression NVARCHAR(50), @PageIndex INT, @PageSize INTAS -- SET NOCOUNT ON added to prevent extra result sets from-- interfering with SELECT statements.SET NOCOUNT ON; IF ((SELECT [dbo].[udf_OrderByExists](&#x27;dbo.Products&#x27;, @SortExpression)) = 0) SET @SortExpression = &#x27;Name&#x27; DECLARE @sql AS NVARCHAR(MAX), @ParamDefinition AS NVARCHAR(MAX), @StartRowIndex INT, @RecordCount INT SELECT @RecordCount = COUNT([ProductID]) FROM [Products] IF @PageIndex = 0 SET @PageIndex = 1IF @PageSize = 0 SET @PageSize = @RecordCountSET @StartRowIndex = ((@PageIndex * @PageSize) - @PageSize) + 1SET @ParamDefinition = N&#x27;@paramStartRowIndex INT, @paramPageSize INT&#x27; SET @sql = N&#x27;SELECT [ProductID], [Name], [Description], [Price]FROM (SELECT [ProductID], [Name], [Description], [Price], ROW_NUMBER() OVER(ORDER BY &#x27; + @SortExpression + &#x27;) AS [RowNumber]FROM [Products]) AS [Prods]WHERE [RowNumber] BETWEEN @paramStartRowIndex AND (@paramStartRowIndex + @paramPageSize) - 1&#x27; -- For testing--PRINT @sql--PRINT @StartRowIndex EXEC sp_executesql @sql, @ParamDefinition, @paramStartRowIndex = @StartRowIndex, @paramPageSize = @PageSize SELECT @RecordCount AS [RecordCount] As you can see, by calling **udf_OrderByExists **and passing in the parameters, if the order by does not fit the table, we then change it to be something known and valid. ConclusionWith a simple and portable user defined function, we can ensure that the order by clauses going into our paging stored procedures are validated thus keeping integrity. It isn’t fun having to write and maintain dynamic SQL in stored procedures, but it can be done and also made a little bit safer. One last tip: Always use the sp_executesql, as this will tell the SQL server that the execution plan should be cached for re-use. Hope this helps!"},{"title":"The Private Access Modifier Can Do That?","slug":"The-private-access-modifier-can-do-that","path":"2008/10/08/The-private-access-modifier-can-do-that/","permalink":"https://iramellor.com/2008/10/08/The-private-access-modifier-can-do-that/","excerpt":"","keywords":"","text":"If you look up accessibility levels on the MSDN web site, it will tell you that the accessibility of the private access modifier is limited to the containing type. I ran into an instance that showed me the direct meaning of this statement. The scenario I had was this: I wanted to have the ability to make an object read only. That is the original object however, if a clone was made then the object could be modified again because it wasn’t the original object. Of course this is a simple task, we get to go back and visit my good friend ICloneable. So we start off by making our data object, putting in the ability to mark it read only and giving it the ability to clone itself. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Lion : ICloneable&#123; public Lion() &#123; &#125; public Lion(string name) &#123; this.Name = name; &#125; private bool _isReadOnly; public bool IsReadOnly &#123; get &#123; return _isReadOnly; &#125; &#125; private string _name; public string Name &#123; get &#123; return _name; &#125; set &#123; if (_isReadOnly) throw new ReadOnlyException(&quot;This object is read only&quot;); _name = value; &#125; &#125; public void MakeReadOnly() &#123; _isReadOnly = true; &#125; #region ICloneable Members public Lion Clone() &#123; Lion result = (Lion)((ICloneable)this).Clone(); result._isReadOnly = false; return result; &#125; object ICloneable.Clone() &#123; return this.MemberwiseClone(); &#125; #endregion&#125; Take a look at line #43 above. During the cloning process, you can set the private variable _isReadOnly on the newly cloned object! For some reason, I was under the impression that any and all private fields and methods were private to that instance of the object. This would mean that all private members of the cloned object would have to be called in the cloned object. To my surprise, this is not the case at all. After changing the _isReadOnly field of the cloned object, the object that was cloned will still remain read only. The cloned object will remain editable until the MakeReadOnly() method is called on it. ConclusionAll fields and methods with the private access modifier are exposed at any time as long as you are in the containing type. The implications of this are that if you clone an object you will have access to the private members of the newly created object. This can be extremely useful, especially if you want a specific action to be performed on a cloned object but you don’t want to explicitly call that action publicly. Hope this helps!"},{"title":"ASP.NET Ajax, JQuery & JSON Date Serialization","slug":"ASP-NET-Ajax-JQuery-JSON-Date-Serialization","path":"2008/09/23/ASP-NET-Ajax-JQuery-JSON-Date-Serialization/","permalink":"https://iramellor.com/2008/09/23/ASP-NET-Ajax-JQuery-JSON-Date-Serialization/","excerpt":"","keywords":"","text":"A little while back I came across a great post on how to use JQuery to do more efficient client side paging by Dave Ward. The sample shows you how to use JQuery to do Ajax callbacks for client side paging using a grid template. After downloading the demo and parsing through it all, I found a lot of things I really liked and even came across a little gotchya with the way ASP.NET serializes dates in JSON. One part I really enjoyed about this sample is that your objects on the server are translated into client side objects. So Order.OrderID or Order.ShippingAddress.ShipName would work the same on the client and server side of the programming. The jtemplates add-in allows you to name your active object of the collection you are looping through a lot like .NET like so: 123456789101112131415161718192021&lt;tbody&gt; &#123;#foreach $T.d as order&#125; &lt;tr&gt; &lt;td&gt; &#123;$T.order.OrderID&#125; &lt;/td&gt; &lt;td&gt; &#123;$T.order.ShippingAddress.ShipName&#125; &lt;/td&gt; &lt;td&gt; &#123;DateDeserialize($T.order.OrderDate).format(&#x27;MM/dd/yyyy&#x27;)&#125; &lt;/td&gt; &lt;td&gt; &#123;DateDeserialize($T.order.RequiredDate).format(&#x27;MM/dd/yyyy&#x27;)&#125; &lt;/td&gt; &lt;td&gt; &#123;$T.order.ShippingAddress.ShipCountry&#125; &lt;/td&gt; &lt;/tr&gt; &#123;#/for&#125;&lt;/tbody&gt; As you can see the order object is used in the jtemplates code just like in .NET code. You may have noticed the DateDeserialize() function followed by the extension method .format() in the snipped above. This is due to some date deserialization issues I ran into. The signature for the DateDeserialize method is as so: 123function DateDeserialize(dateStr) &#123; return eval(&#x27;new&#x27; + dateStr.replace(/\\//g, &#x27; &#x27;));&#125; This method is basically returning the evaluation of the date returned by the .NET framework (ex: &#x2F;Date(894427200000)&#x2F;), replacing the &#x2F; with a space with the keyword &quot;new&quot; in front of it. This will return us a JavaScript Date object. Then I&#39;m using the .format() extension method from the included MSAjax framework. It took me a little while to figure out, but once I did I fell in love. You can&#39;t put a price on full on object-oriented programming! Special thanks to Dave Ward for opening my eyes to the power of JQuery! Hope this helps!"},{"title":"LINQ Distinct, a DataTable and the IEqualityComparer","slug":"LINQ-Distinct-a-DataTable-and-the-IEqualityComparer","path":"2008/08/26/LINQ-Distinct-a-DataTable-and-the-IEqualityComparer/","permalink":"https://iramellor.com/2008/08/26/LINQ-Distinct-a-DataTable-and-the-IEqualityComparer/","excerpt":"","keywords":"","text":"In a recent situation I was trying to pull some aggregates out of a DataTable using LINQ. I needed to get the rows of the DataTable with a Distinct clause, but my aggregates would be on other columns of the row. The problem is that when you call LINQ’s Distinct() extension method with no arguments, it uses the &quot;default IEqualityComparer&quot;. This means that it will work if you use the Select() extension method, only returning the column you want the distinct on. Well that works great, unless you need more columns from the DataTable. The solution here is simple. Write a custom DataRow comparer that compares the DataRow against the column you are trying to put the distinct on. Here is an example: 12345678910111213141516public class PersonDataRowComparer : IEqualityComparer&lt;DataRow&gt;&#123; #region IEqualityComparer&lt;DataRow&gt; Members public bool Equals(DataRow x, DataRow y) &#123; return (x.Field&lt;int&gt;(&quot;PersonID&quot;) == y.Field&lt;int&gt;(&quot;PersonID&quot;)); &#125; public int GetHashCode(DataRow obj) &#123; return obj.ToString().GetHashCode(); &#125; #endregion&#125; Once we inherit IEqualityComparer&lt;T&gt; (T being the type we want to do the comparison on) all we do is fill in the Equals() and the GetHashCode() methods. In the Equals() method, we just tell the DataRows to compare the fields &quot;PersonID&quot; and return if they are equal. This will tell LINQ if the DataRow is distinct or not. Hope this helps!"},{"title":"Strongly Typed Dynamic User Controls","slug":"Strongly-Typed-Dynamic-User-Controls","path":"2008/06/03/Strongly-Typed-Dynamic-User-Controls/","permalink":"https://iramellor.com/2008/06/03/Strongly-Typed-Dynamic-User-Controls/","excerpt":"","keywords":"","text":"A short time ago I was confronted with a serious problem. What I needed to do was dynamically choose a UserControl as well as fire methods from that UserControl. The problem lies in the fact that a UserControl does not implement my custom methods that I needed for my controls. Each control was similar and would have the same methods but it would have different display characteristics. That was when I had a small epiphany. Why can’t I just make an abstract base class? Well the answer is you can! Sometimes I am prone to forget how .NET allows me to customize pre-defined classes. What we can do is create an abstract base class that inherits the UserControl class, then have our UserControls inherit from our base class. First we will create our abstract base class. 12345678910111213141516171819202122using System;using System.Data;using System.Configuration;using System.Linq;using System.Web;using System.Web.Security;using System.Web.UI;using System.Web.UI.HtmlControls;using System.Web.UI.WebControls;using System.Web.UI.WebControls.WebParts;using System.Xml.Linq;/// &lt;summary&gt;/// Base class to be inherited by a UserControl that displays the date/// &lt;/summary&gt;public abstract class DateTimeDisplayControl : UserControl&#123; /// &lt;summary&gt; /// Updates the date time inside the user control. /// &lt;/summary&gt; public abstract void UpdateDateTime();&#125; So in the snippet above, we have created a class called DateTimeDisplayControl. This inherits from UserControl and will have to override the abstract method UpdateDateTime(). Now we can create a couple of UserControls that inherit from our DisplayDateTimeControl class. The first control will be called &quot;ControlOne&quot;. Here is the *.ascx code: 1234567&lt;%@ Control Language=&quot;C#&quot; AutoEventWireup=&quot;true&quot; CodeFile=&quot;ControlOne.ascx.cs&quot; Inherits=&quot;UserControls_ControlOne&quot; %&gt;&lt;p&gt;User control one&lt;/p&gt;&lt;asp:UpdatePanel ID=&quot;udp1&quot; runat=&quot;server&quot; UpdateMode=&quot;Conditional&quot;&gt; &lt;ContentTemplate&gt; &lt;asp:Label ID=&quot;lblDateTime&quot; runat=&quot;server&quot; /&gt; &lt;/ContentTemplate&gt;&lt;/asp:UpdatePanel&gt; Here is the code behind: 123456789101112131415161718192021222324252627using System;using System.Collections;using System.Configuration;using System.Data;using System.Linq;using System.Web;using System.Web.Security;using System.Web.UI;using System.Web.UI.HtmlControls;using System.Web.UI.WebControls;using System.Web.UI.WebControls.WebParts;using System.Xml.Linq;public partial class UserControls_ControlOne : DateTimeDisplayControl&#123; protected void Page_Load(object sender, EventArgs e) &#123; if (!Page.IsPostBack) UpdateDateTime(); &#125; public override void UpdateDateTime() &#123; lblDateTime.Text = DateTime.Now.ToString(); udp1.Update(); &#125;&#125; As you can see, ControlOne contains an UpdatePanel with a Label inside of it. The Label will display the date and time. We will call our second control &quot;ControlTwo&quot; and it will look exactly like ControlOne, only it will say &quot;User control two&quot; inside of it. Now we will create the actual *.aspx page to display the controls. Here is the *.aspx code 1234567891011121314151617181920212223242526272829303132&lt;%@ Page Language=&quot;C#&quot; AutoEventWireup=&quot;true&quot; CodeFile=&quot;Default.aspx.cs&quot; Inherits=&quot;_Default&quot; %&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&amp;quot;&gt;&lt;head runat=&quot;server&quot;&gt; &lt;title&gt;Strongly Typed Dynamic User Controls&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form id=&quot;form1&quot; runat=&quot;server&quot;&gt; &lt;asp:ScriptManager ID=&quot;sm1&quot; runat=&quot;server&quot; /&gt; &lt;asp:UpdatePanel ID=&quot;udp&quot; runat=&quot;server&quot; UpdateMode=&quot;Conditional&quot;&gt; &lt;ContentTemplate&gt; &lt;asp:Panel ID=&quot;pnlContent&quot; runat=&quot;server&quot; /&gt; &lt;/ContentTemplate&gt; &lt;Triggers&gt; &lt;asp:AsyncPostBackTrigger ControlID=&quot;btnUseControlOne&quot; EventName=&quot;Click&quot; /&gt; &lt;asp:AsyncPostBackTrigger ControlID=&quot;btnUseControlTwo&quot; EventName=&quot;Click&quot; /&gt; &lt;asp:AsyncPostBackTrigger ControlID=&quot;btnUpdateDateTime&quot; EventName=&quot;Click&quot; /&gt; &lt;/Triggers&gt; &lt;/asp:UpdatePanel&gt; &lt;p&gt; &lt;asp:Button ID=&quot;btnUseControlOne&quot; runat=&quot;server&quot; Text=&quot;Use Control One&quot; onclick=&quot;btnUseControlOne_Click&quot; /&gt;&amp;nbsp; &lt;asp:Button ID=&quot;btnUseControlTwo&quot; runat=&quot;server&quot; Text=&quot;Use Control Two&quot; onclick=&quot;btnUseControlTwo_Click&quot; /&gt;&amp;nbsp; &lt;asp:Button ID=&quot;btnUpdateDateTime&quot; runat=&quot;server&quot; Text=&quot;Update Content&quot; onclick=&quot;btnUpdateDateTime_Click&quot; /&gt; &lt;/p&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; Here is the code behind: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475using System;using System.Configuration;using System.Data;using System.Linq;using System.Web;using System.Web.Security;using System.Web.UI;using System.Web.UI.HtmlControls;using System.Web.UI.WebControls;using System.Web.UI.WebControls.WebParts;using System.Xml.Linq;public partial class _Default : System.Web.UI.Page&#123; private string _controlVirtualPath = string.Empty; private DateTimeDisplayControl _DateTimeDisplayControl = null; private string ControlVirtualPath &#123; get &#123; if (string.IsNullOrEmpty(_controlVirtualPath)) _controlVirtualPath = ViewState[&quot;ControlVirtualPath&quot;].ToString(); ViewState[&quot;ControlVirtualPath&quot;] = _controlVirtualPath; if (string.IsNullOrEmpty(_controlVirtualPath)) throw new ApplicationException(&quot;The control virtual path was not found&quot;); return _controlVirtualPath; &#125; &#125; private DateTimeDisplayControl LoadedAjaxControl &#123; get &#123; if (_DateTimeDisplayControl == null) &#123; _DateTimeDisplayControl = (DateTimeDisplayControl)Page.LoadControl(ControlVirtualPath); &#125; return _DateTimeDisplayControl; &#125; &#125; private void LoadAndDisplayUserControl() &#123; pnlContent.Controls.Add(LoadedAjaxControl); &#125; private void LoadAndDisplayUserControl(string controlVirtualPath) &#123; _controlVirtualPath = controlVirtualPath; pnlContent.Controls.Add(LoadedAjaxControl); &#125; protected void Page_Load(object sender, EventArgs e) &#123; if (!Page.IsPostBack) LoadAndDisplayUserControl(&quot;~/UserControls/ControlOne.ascx&quot;); &#125; protected void btnUseControlOne_Click(object sender, EventArgs e) &#123; LoadAndDisplayUserControl(&quot;~/UserControls/ControlOne.ascx&quot;); &#125; protected void btnUseControlTwo_Click(object sender, EventArgs e) &#123; LoadAndDisplayUserControl(&quot;~/UserControls/ControlTwo.ascx&quot;); &#125; protected void btnUpdateDateTime_Click(object sender, EventArgs e) &#123; LoadAndDisplayUserControl(); LoadedAjaxControl.UpdateDateTime(); &#125;&#125; As you may see, the *.aspx page will load up ControlOne by default. There are 3 buttons on the page that will allow you to swap out ControlOne and ControlTwo as well as call the UpdateDateTime() method of the controls. That is all there is to it! One important note is that I am using a private property to get the loaded control, this is important to note because you will need to call that UpdateDateTime() method on the instance of the control that you rendered to the page. I don’t know why I didn’t think of this long ago, but I hope you will find it as useful as I did! Happy coding!"},{"title":"Using the Event Model: Throwing and Handling Custom Events","slug":"Using-The-Event-Model-Throwing-and-Handling-Custom-Events","path":"2008/04/21/Using-The-Event-Model-Throwing-and-Handling-Custom-Events/","permalink":"https://iramellor.com/2008/04/21/Using-The-Event-Model-Throwing-and-Handling-Custom-Events/","excerpt":"","keywords":"","text":"If you haven’t tried using the event model in .NET you don’t know what you’re missing. If this is the case, then I’m glad you’re here. Events are a very nice way to add flexibility to your projects and eliminate cross cutting concerns. You can use them for a variety of things including validation and logging. You can think of an event as sort of an All Points Bulletin (APB) throughout your application. Once you declare and throw an event, every place in your code that has an event handler for that event will be executed. Events can be both static or per instance. You use events every time you build an ASP.NET website. The Page_Load event, Button_Click event, etc… It is like an application wide notification that something is happening. An important note is that all event handlers that have been moved to the call stack will be fired. So when you call out to your custom event, all objects that are in the call stack with an event handler for that event will be fired. Another thing to keep in mind is that there is no guaranteed order in which the events will be fired. If you are in need of doing something that requires a specific order, you should use more events or take another approach entirely. In this project, we will create some events and handle them in a logging system. The first thing we will need to do is set up an event delegate to strongly type our event. Along with doing that, I like to setup some custom event arguments that will take in the object(s) that I will be dealing with during the event. 12345678910111213141516171819202122232425262728293031using System; using System.Collections.Generic; //Delegate for a PersonEvent public delegate void PersonEvent(PersonEventArgs e); public class PersonEventArgs : EventArgs &#123; public PersonEventArgs() &#123; &#125; public PersonEventArgs(Person person) &#123; this.Person = person; &#125; public PersonEventArgs(List&lt;Person&gt; personList) &#123; this.PersonList = personList; &#125; //Person the action will be on public Person Person &#123; get; private set; &#125; //List of person the action will be on public List&lt;Person&gt; PersonList &#123; get; private set; &#125; //For canceling action public bool Cancel &#123; get; set; &#125; &#125; Ok, Now all we have to do is declare and throw our events. When declaring our events, they will be of the type PersonEvent. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108using System.Collections.Generic; using System.ComponentModel; [DataObject(true)] public class PersonBLL &#123; //Declare events public static event PersonEvent Pre_Get; public static event PersonEvent Post_Get; public static event PersonEvent Pre_Insert; public static event PersonEvent Post_Insert; public static event PersonEvent Pre_Update; public static event PersonEvent Post_Update; public static event PersonEvent Pre_Delete; public static event PersonEvent Post_Delete; [DataObjectMethod(DataObjectMethodType.Select)] public List&lt;PersonPresentationShell&gt; GetPeople() &#123; //Call out to event handler if (Pre_Get != null) &#123; PersonEventArgs args = new PersonEventArgs(); Pre_Get(args); if (args.Cancel) return null; &#125; List&lt;PersonPresentationShell&gt; result = new List&lt;PersonPresentationShell&gt;(); List&lt;Person&gt; personList = DataAccessFactory.GetPeople(); foreach (Person item in personList) &#123; result.Add(new PersonPresentationShell(item)); &#125; //Call out to event handler if (Post_Get != null) &#123; PersonEventArgs args = new PersonEventArgs(personList); Post_Get(args); if (args.Cancel) return null; &#125; return result; &#125; [DataObjectMethod(DataObjectMethodType.Update)] public void UpdatePerson(PersonPresentationShell p) &#123; //Call out to event handler if (Pre_Update != null) &#123; PersonEventArgs args = new PersonEventArgs(p.Person); Pre_Update(args); if (args.Cancel) return; &#125; DataAccessFactory.UpdatePerson(p.Person); //Call out to event handler if (Post_Update != null) &#123; PersonEventArgs args = new PersonEventArgs(p.Person); Post_Update(args); &#125; &#125; [DataObjectMethod(DataObjectMethodType.Delete)] public void DeletePerson(PersonPresentationShell p) &#123; //Call out to event handler if (Pre_Delete != null) &#123; PersonEventArgs args = new PersonEventArgs(p.Person); Pre_Delete(args); if (args.Cancel) return; &#125; DataAccessFactory.DeletePerson(p.Person); //Call out to event handler if (Post_Delete != null) &#123; PersonEventArgs args = new PersonEventArgs(p.Person); Post_Delete(args); &#125; &#125; [DataObjectMethod(DataObjectMethodType.Insert)] public void InsertPerson(PersonPresentationShell p) &#123; //Call out to event handler if (Pre_Insert != null) &#123; PersonEventArgs args = new PersonEventArgs(p.Person); Pre_Insert(args); if (args.Cancel) return; &#125; DataAccessFactory.InsertPerson(p.Person); //Call out to event handler if (Post_Insert != null) &#123; PersonEventArgs args = new PersonEventArgs(p.Person); Post_Insert(args); &#125; &#125; &#125; There we have it! An event will now be thrown before and after every get, insert, update and delete. Now we have to set up some event handlers in our logging object. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677using System; using System.IO; using System.Web; public class Logger &#123; //Set the log file location private static string _logFileLocation = HttpContext.Current.Server.MapPath(&quot;~/App_Data/logfile.log&quot;); static Logger() &#123; //Attach event handlers PersonBLL.Pre_Delete += new PersonEvent(PersonBLL_Pre_Delete); PersonBLL.Post_Delete += new PersonEvent(PersonBLL_Post_Delete); PersonBLL.Pre_Get += new PersonEvent(PersonBLL_Pre_Get); PersonBLL.Post_Get += new PersonEvent(PersonBLL_Post_Get); PersonBLL.Pre_Insert += new PersonEvent(PersonBLL_Pre_Insert); PersonBLL.Post_Insert += new PersonEvent(PersonBLL_Post_Insert); PersonBLL.Pre_Update += new PersonEvent(PersonBLL_Pre_Update); PersonBLL.Post_Update += new PersonEvent(PersonBLL_Post_Update); &#125; static void PersonBLL_Post_Update(PersonEventArgs e) &#123; WriteToLogFile(&quot;PersonId: &quot; + e.Person.PersonId.ToString() + &quot; - &quot; + e.Person.FirstName + &quot; &quot; + e.Person.LastName + &quot; was updated”); &#125; static void PersonBLL_Pre_Update(PersonEventArgs e) &#123; WriteToLogFile(&quot;PersonId: &quot; + e.Person.PersonId.ToString() + &quot; - &quot; + e.Person.FirstName + &quot; &quot; + e.Person.LastName + &quot; is about to be updated”); &#125; static void PersonBLL_Post_Insert(PersonEventArgs e) &#123; WriteToLogFile(&quot;PersonId: &quot; + e.Person.PersonId.ToString() + &quot; - &quot; + e.Person.FirstName + &quot; &quot; + e.Person.LastName + &quot; was inserted”); &#125; static void PersonBLL_Pre_Insert(PersonEventArgs e) &#123; WriteToLogFile(&quot;PersonId: &quot; + e.Person.PersonId.ToString() + &quot; - &quot; + e.Person.FirstName + &quot; &quot; + e.Person.LastName + &quot; is about to be inserted”); &#125; static void PersonBLL_Post_Get(PersonEventArgs e) &#123; WriteToLogFile(&quot;The people were gotten”); &#125; static void PersonBLL_Pre_Get(PersonEventArgs e) &#123; WriteToLogFile(&quot;The people are about to be gotten”); &#125; static void PersonBLL_Post_Delete(PersonEventArgs e) &#123; WriteToLogFile(&quot;PersonId: &quot; + e.Person.PersonId.ToString() + &quot; - &quot; + e.Person.FirstName + &quot; &quot; + e.Person.LastName + &quot; was deleted”); &#125; static void PersonBLL_Pre_Delete(PersonEventArgs e) &#123; WriteToLogFile(&quot;PersonId: &quot; + e.Person.PersonId.ToString() + &quot; - &quot; + e.Person.FirstName + &quot; &quot; + e.Person.LastName + &quot; is about to be deleted”); &#125; public static void WriteToLogFile(string message) &#123; DateTime now = DateTime.Now; using(StreamWriter sw = File.AppendText(_logFileLocation)) &#123; sw.WriteLine(now.ToString() + &quot; - &quot; + message); &#125; &#125; &#125; Finally, we have to create an instance of our logger class in the Global.asax file to attach our event handlers to our events when the application starts. 123456void Application_Start(object sender, EventArgs e) &#123; //Create an instance of the logger //To attach event handlers Logger logger = new Logger(); &#125; There we have it. Now on every CRUD operation in our application, a log entry will be written with some data about that action. Once you get the hang of it events become extremely useful. One big instance I like to use it for is authorization of performing an action in a membership and roles scenario. Hope this helps!"},{"title":"Clean Up ASP.NETs Head Tag With ControlAdapters","slug":"Clean-Up-ASP-NETs-Head-Tag-With-ControlAdapters","path":"2008/04/14/Clean-Up-ASP-NETs-Head-Tag-With-ControlAdapters/","permalink":"https://iramellor.com/2008/04/14/Clean-Up-ASP-NETs-Head-Tag-With-ControlAdapters/","excerpt":"","keywords":"","text":"Ok, if you’re anything like me you absolutely gag when you see the rendered content of the ASP.NET head tag. It is all rendered out inline for some reason. I’m not 100% sure about the affects of it on web marketing, but I know one thing is for sure… It certainly doesn’t help your rankings any. At the very least it looks gross and it can be easily fixed with some portable c# files that you can include in any project. I found a reference here about it, so I picked it up and ran with it. A couple of good things to note is the placement of some key pieces for control adapters in the .NET framework. The ControlAdapter class should be inherited for every control adapter you create, it can be found in the System.Web.UI.Adapters namespace. All of the tags we will be overriding belong to the System.Web.UI.HtmlControls namespace. The first tag we will override is the head tag itself. 1234567891011121314151617181920using System.Web.UI; using System.Web.UI.Adapters; using System.Web.UI.HtmlControls; namespace Rollem.ControlAdapters &#123; public class HtmlHeadAdapter : ControlAdapter &#123; protected override void Render(HtmlTextWriter writer) &#123; HtmlHead headTag = (HtmlHead)this.Control; writer.WriteBeginTag(&quot;head&quot;); if (!string.IsNullOrEmpty(headTag.ID)) writer.WriteAttribute(&quot;id&quot;, headTag.ClientID); writer.Write(HtmlTextWriter.TagRightChar); foreach (Control item in headTag.Controls) item.RenderControl(writer); writer.WriteLine(&quot;&quot;); &#125; &#125; &#125; Next we are on to the title tag. 12345678910111213141516using System.Web.UI; using System.Web.UI.Adapters; namespace Rollem.ControlAdapters &#123; public class HtmlTitleAdapter : ControlAdapter &#123; protected override void Render(HtmlTextWriter writer) &#123; writer.WriteLine(); writer.WriteFullBeginTag(&quot;title&quot;); writer.Write(Page.Title); writer.WriteEndTag(&quot;title&quot;); writer.WriteLine(); &#125; &#125; &#125; Now the link tags. 1234567891011121314151617181920212223242526using System.Collections; using System.Web.UI; using System.Web.UI.Adapters; using System.Web.UI.HtmlControls; namespace Rollem.ControlAdapters &#123; public class HtmlLinkAdapter : ControlAdapter &#123; protected override void Render(HtmlTextWriter writer) &#123; HtmlLink linkTag = (HtmlLink)this.Control; writer.Write(&quot;&lt;link&quot;); AttributeCollection attributes = linkTag.Attributes; IEnumerator keys = linkTag.Attributes.Keys.GetEnumerator(); while (keys.MoveNext()) &#123; string key = (string)keys.Current; if (key.ToLower() == &quot;href&quot; &amp;&amp; attributes[key].Contains(&quot;~&quot;)) writer.WriteAttribute(key, linkTag.ResolveClientUrl(attributes[key])); else writer.WriteAttribute(key, attributes[key]); writer.WriteLine(&quot; /&gt;&quot;); &#125; &#125; &#125;&#125; Last but not least, the meta tags. 1234567891011121314151617181920using System.Web.UI; using System.Web.UI.Adapters; using System.Web.UI.HtmlControls; namespace Rollem.ControlAdapters &#123; public class HtmlMetaAdapter : ControlAdapter &#123; protected override void Render(HtmlTextWriter writer) &#123; HtmlMeta metaTag = (HtmlMeta)this.Control; writer.WriteBeginTag(&quot;meta&quot;); if (!string.IsNullOrEmpty(metaTag.HttpEquiv)) writer.WriteAttribute(&quot;http-equiv&quot;, metaTag.HttpEquiv); if (!string.IsNullOrEmpty(metaTag.Name)) writer.WriteAttribute(&quot;name&quot;, metaTag.Name); writer.WriteAttribute(&quot;content&quot;, metaTag.Content); writer.WriteLine(HtmlTextWriter.SelfClosingTagEnd); &#125; &#125; &#125; Now all we have to do is setup a *.browser file in the App_Browsers folder to map the control adapter overrides. 1234567891011121314&lt;browsers&gt; &lt;browser refID=&quot;Default&quot;&gt; &lt;controlAdapters&gt; &lt;adapter controlType=&quot;System.Web.UI.HtmlControls.HtmlHead&quot; adapterType=&quot;Rollem.ControlAdapters.HtmlHeadAdapter&quot; /&gt; &lt;adapter controlType=&quot;System.Web.UI.HtmlControls.HtmlTitle&quot; adapterType=&quot;Rollem.ControlAdapters.HtmlTitleAdapter&quot; /&gt; &lt;adapter controlType=&quot;System.Web.UI.HtmlControls.HtmlMeta&quot; adapterType=&quot;Rollem.ControlAdapters.HtmlMetaAdapter&quot; /&gt; &lt;adapter controlType=&quot;System.Web.UI.HtmlControls.HtmlLink&quot; adapterType=&quot;Rollem.ControlAdapters.HtmlLinkAdapter&quot; /&gt; &lt;/controlAdapters&gt; &lt;/browser&gt; &lt;/browsers&gt; Now if we right click and view source we will see a nice clean head tag. Don’t live a moment longer with that ugly ASP.NET rendered head tag!&nbsp; Hope this helps!"}],"categories":[],"tags":[]}